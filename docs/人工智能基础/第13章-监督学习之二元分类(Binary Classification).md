# 第13章-监督学习之二元分类(Binary Classification)

---

## 分类 vs. 回归

**分类 (Classification)** 和 **回归 (Regression)** 都属于 **监督学习 (Supervised Learning)**，它们的 **训练、验证和评估流程相似**，但预测目标不同：

| 任务类型 | 预测目标 | 示例 |
|----------|---------|------|
| **回归** | **连续数值** | 预测房价、销量、气温 |
| **分类** | **类别** | 预测是否购买、是否患病 |

**主要区别：**
- **回归** 预测 **具体数值**，如明天的气温是多少度 。
- **分类** 预测 **类别**，如某封邮件是垃圾邮件还是正常邮件。
- **分类模型** 计算 **类别的概率**，然后选择 **概率最高的类别** 作为预测值。

---

## 什么是二元分类？

**二元分类 (Binary Classification)** 指 **只能预测两个可能类别** 的模型，例如：
- **是否患病**（是 / 否）
- **邮件是否为垃圾邮件**（垃圾 / 正常）
- **贷款是否违约**（违约 / 不违约）

**数据结构**
- **特征 (x)**：输入数据，例如血糖值。
- **目标值 (y)**：标签，只有 **0 或 1**（未患病 / 患病）。

### 示例：血糖预测糖尿病
| 血糖 (x) | 糖尿病？ (y) |
|----------|------------|
| 67       | 0          |
| 103      | 1          |
| 114      | 1          |
| 72       | 0          |
| 116      | 1          |
| 65       | 0          |

**目标**：
- **输入血糖值 (x)** → 预测 **糖尿病的概率**：
  - **接近 1.0** → 患病概率高
  - **接近 0.0** → 患病概率低

---

## 训练二元分类模型  

### **常见分类算法**
**逻辑回归 (Logistic Regression)** - 通过 **S 形 (Sigmoid) 函数计算概率** 
**决策树 (Decision Tree)** - 通过 **规则路径分类** 
**随机森林 (Random Forest)** - 通过 **多个决策树集成分类**  
**支持向量机 (SVM)** - 通过 **超平面分隔类别**
**神经网络 (Neural Network)** - **复杂数据分类**

### 逻辑回归计算概率
逻辑回归计算：
$$ P(y = 1 | x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}} $$
其中：
- `P(y=1 | x)` 是 **预测患病的概率**
- `β0` 和 `β1` 是 **模型参数**
- `e` 是 **自然对数底数**

示例：
- **若某患者的糖尿病概率 = 0.7**：
  - **患病概率 70%**
  - **未患病概率 30%**

---

## 评估二元分类模型  

### **混淆矩阵 (Confusion Matrix)**

混淆矩阵 (Confusion Matrix) 直观展示 **预测值 (ŷ) 和 实际值 (y) 之间的对比**：

**测试数据**
| **血糖 (x)** | **实际糖尿病 (y)** | **预测糖尿病 (ŷ)** |
|--------------|------------------|------------------|
| 66           | 0                | 0                |
| 107          | 1                | 1                |
| 112          | 1                | 1                |
| 71           | 0                | 0                |
| 87           | 1                | 0                |
| 89           | 1                | 1                |

**混淆矩阵可视化**
| 预测 \ 实际 | 0 (未患病) | 1 (患病) |
|-------------|----------|----------|
| **0 (预测未患病)** | 2 (TN) | 1 (FN) |
| **1 (预测患病)**  | 0 (FP) | 3 (TP) |

**图示**：
![混淆矩阵](/learning-notes/materials/file-VQsuGGaiSqgius8PurzrGK.png)  

**解释**
- **True Positive (TP)** = 3 → **正确预测为患病**
- **True Negative (TN)** = 2 → **正确预测为未患病**
- **False Positive (FP)** = 0 → **错误预测为患病**
- **False Negative (FN)** = 1 → **错误预测为未患病**

---

## 评估指标  

### **准确率 (Accuracy)**
衡量整体正确率：
$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$
计算：
$$
Accuracy = \frac{3 + 2}{3 + 2 + 0 + 1} = \frac{5}{6} = 0.83
$$  
✅ **83% 预测正确**。

---

### **召回率 (Recall)**
衡量 **正确识别出患病者的比例**：
$$
Recall = \frac{TP}{TP + FN}
$$
计算：
$$
Recall = \frac{3}{3+1} = \frac{3}{4} = 0.75
$$  
**75% 的糖尿病患者被正确识别**。

---

### **精准率 (Precision)**
衡量 **预测为糖尿病的人中，实际患病的比例**：
$$
Precision = \frac{TP}{TP + FP}
$$
计算：
$$
Precision = \frac{3}{3+0} = \frac{3}{3} = 1.0
$$  
**所有预测的糖尿病患者都是真实患者**。

---

### **F1 分数 (F1 Score)**
综合精准率和召回率：
$$
F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}
$$
计算：
$$
F1 = \frac{2 \times 1.0 \times 0.75}{1.0 + 0.75} = \frac{1.5}{1.75} = 0.86
$$  
**模型整体表现 F1 = 0.86**。

---

## 总结

**二元分类模型用于预测两种类别，如“有病 or 无病”**。  
**逻辑回归是常见的二元分类算法，使用 S 形曲线计算概率**。  
**评估模型时不能只看准确率，还要关注召回率、精准率、F1 分数等指标**。  

**进一步学习**：
- [Scikit-learn 逻辑回归](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  
- [TensorFlow 分类教程](https://www.tensorflow.org/tutorials/keras/classification)  

📢 **欢迎 Star ⭐ 本仓库，获取更多 AI 资源！**
