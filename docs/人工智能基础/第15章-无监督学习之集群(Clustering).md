# 第15章-无监督学习之集群(Clustering)
---

## 什么是聚类 (Clustering)？  

**聚类** 是 **无监督学习 (Unsupervised Learning)** 方法之一，它根据 **数据特征的相似性**，将观测数据分组到不同的 **簇 (Clusters)** 中。

**特点**：
- **无标签**：训练过程中 **没有已知类别 (y)**，模型会 **自动发现数据中的模式**。
- **数据点相似性**：聚类模型会将相似的数据点聚合到同一个簇中，而不同簇之间的数据点尽可能不同。

**应用场景**：
- **客户细分**：根据消费习惯，将客户分组。
- **图像分割**：将图像像素点划分成不同区域。
- **基因数据分析**：基于 DNA 数据对物种进行分类。

---

## 示例：花朵聚类

假设一位植物学家观察了一组花朵，并记录了每朵花的：
- **叶子数量 (x₁)**
- **花瓣数量 (x₂)**

**数据示例**
| **叶子 (x₁)** | **花瓣 (x₂)** |
|--------------|--------------|
| 0            | 5            |
| 0            | 6            |
| 1            | 3            |
| 1            | 3            |
| 1            | 6            |
| 1            | 8            |
| 2            | 3            |
| 2            | 7            |
| 2            | 8            |

**目标**：
- 不是去识别不同类型的花，而是根据 **叶子和花瓣的数量**，**自动发现数据的自然分组 (Clusters)**。
- **聚类算法** 会基于这些特征找到 **花的类别**，而 **不依赖于已有的标签**。

---

## 训练聚类模型  

### **K-Means 聚类算法**
**K-Means** 是最常见的聚类算法，工作流程如下：

### **1. 数据向量化**
**转换特征为向量坐标**
- **叶子数量 (x₁)**
- **花瓣数量 (x₂)**
- 每朵花可以表示为坐标 **[x₁, x₂]**，并在 **二维坐标系** 中绘制。

### **2. 选择聚类数目 (k)**
**确定要分成多少个簇 (Clusters)**
- **k 值** 代表簇的数量，例如：
  - **k=3** → 分成 **3 组**
  - **k=5** → 分成 **5 组**
- 需要 **随机选取 k 个点** 作为 **初始质心 (Centroids)**。

### **3. 数据点分配**
**每个数据点** 分配给 **最近的质心**：
- 计算数据点到质心的 **欧几里得距离 (Euclidean Distance)**：
  $$
  d = \sqrt{(x_1 - c_1)^2 + (x_2 - c_2)^2}
  $$
- 选择 **最近的质心**，形成初始簇。

### **4. 更新质心**
**计算每个簇的中心点**：
- 取 **簇内所有数据点的均值** 作为新的 **质心 (Centroid)**。
- 重新计算 **簇的中心位置**。

### **5. 重新分配数据点**
**数据点重新分配**：
- 由于 **质心已经移动**，某些数据点可能更靠近其他质心，因此需要 **重新分配** 数据点到最近的质心。

### **6. 迭代优化，直到收敛**
**不断调整，直到模型稳定**：
- 质心 **不再移动**（簇变得稳定）。
- 达到 **最大迭代次数**（通常是 **100~500** 次）。

**最终目标**：
- **使得同一簇内的数据点尽可能相似**，不同簇之间的数据点尽可能不同。

![过程](/learning-notes/materials/clustering.gif)  
---

## 评估聚类模型  

**由于聚类模型没有已知的标签**，所以不能直接计算 **准确率**，评估主要基于 **簇内紧密度** 和 **簇间分离度**。

### **1. 簇内平均距离 (Average Distance to Cluster Center)**
- 衡量簇内 **数据点到簇中心的平均距离**。
- **数值越小**，说明簇内部数据点更紧密，聚类效果越好。

### **2. 簇间平均距离 (Average Distance to Other Centers)**
- 衡量簇 **与其他簇的距离**。
- **数值越大**，说明不同簇之间的分离度更高，聚类效果越清晰。

### **3. 最大簇内距离 (Maximum Distance to Cluster Center)**
- **计算某个簇内** **最远的数据点到质心的距离**。
- 若 **最大距离过大**，说明簇的形状较松散，可能需要调整 k 值。

### **4. 轮廓系数 (Silhouette Score)**
**衡量数据点在簇内的紧密程度和不同簇的分离程度**：
$$
S = \frac{b - a}{\max(a, b)}
$$
- `a`：数据点与同簇内其他点的平均距离（簇内紧密度）。
- `b`：数据点与最近邻簇内数据点的平均距离（簇间分离度）。
- **取值范围 [-1, 1]**：
  - **接近 1**：聚类效果好，簇内数据点聚合紧密，簇间分离明显。
  - **接近 0**：簇的结构不明显，可能存在 **重叠**。
  - **小于 0**：簇划分不合理，部分数据点可能被错误分类。

---

## 总结  

**聚类是一种无监督学习方法**，用于 **发现数据中的隐藏模式**。  
**K-Means 是最常见的聚类算法**，通过 **迭代优化** 簇中心点，实现数据分组。  
**评估聚类效果** 主要使用 **簇内紧密度** 和 **簇间分离度**，而不是准确率。  

**进一步学习**：
- [Scikit-learn 聚类教程](https://scikit-learn.org/stable/modules/clustering.html)  
- [K-Means 聚类算法原理](https://en.wikipedia.org/wiki/K-means_clustering)  
- [Python 代码示例](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)  

📢 **欢迎 Star ⭐ 本仓库，获取更多 AI 资源！**

