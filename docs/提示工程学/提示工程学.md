## 什么是提示词（Prompts）？

提示词在与大语言模型（LLMs）进行沟通和引导其行为中扮演着关键角色。它们是用户输入的内容，用来引发模型生成特定的响应。

## 巧妙的设计提示词

有效的提示词设计对实现预期的模型输出至关重要。提示词工程（Prompt Engineering），也称为提示词设计，是一个新兴领域，需要富有创造力和对细节的高度关注。它涉及选择合适的词语、短语、符号和格式，以引导模型生成高质量且相关的文本内容。

如果你已经用过 ChatGPT，你就会发现模型的行为会随着输入提示的不同而发生显著变化。例如，以下两个提示产生完全不同的输出：

提示词1：请告诉我人类的历史。

提示词2：请用三句话告诉我人类的历史。

第一个提示词会生成一份详细报告，而第二个则只输出简洁的摘要。
如果你在构建一个空间有限的用户界面，第二个提示更为适合。通过在提示中加入更多细节，可以进一步细化模型行为，但过度指定也可能导致输出变得无关紧要。作为提示词工程师，你必须在具体性与相关性之间找到平衡点。

## 控制模型行为的参数

当你直接与 LLM 模型交互时，还可以使用其他参数来影响模型行为。例如：

### temperature — 控制“随机性/创造性”

- **定义：** 控制生成文本的随机程度，影响词汇分布的“平滑度”。
- **取值范围：** `0.0` 到 `2.0`
- **常用范围建议：** `0.2 ~ 1.0`
- **说明补充：**
  - 越低越确定（像查字典一样），越高越“发散”（更具创造力但不稳定）。
  - 通常任务：`0.7` 是较常用的折中值。

---

### top-k — 词汇候选的硬限制

- **定义：** 每步生成词时，从概率最高的前 `k` 个词中采样，其他的词一律不考虑。
- **合法范围：** 通常为 `1` 到 `1000+`（视模型和 API 限制）
- **常用范围：** `20` 到 `100`
- **说明补充：**
  - `top-k = 1` 表示“贪婪解码”（greedy decoding），始终选最可能的那个词。
  - 可与 `temperature` 搭配使用以增强或限制创造力。

---

### top-p（nucleus sampling）— 概率累计筛选

- **定义：** 从累计概率加起来达到 `p` 的词集合中随机采样。
- **取值范围：** `0.0 ~ 1.0`，常用值为 `0.8 ~ 0.95`
- **说明补充：**
  - 比 `top-k` 更“自适应”：不限制具体词数，而是根据概率分布动态决定多少候选词。
  - 一般推荐优先使用 `top-p` 而不是 `top-k`，因为更自然。

---

### frequency penalty — 惩罚“词频高的词”

- **定义：** 减少模型重复使用之前**频繁生成的词**的倾向。
- **取值范围：** `0.0 ~ 2.0`，默认 `0`
- **效果：** 增加后输出更加丰富，减少词汇重复。

---

### presence penalty — 惩罚“出现过的词”

- **定义：** 对所有曾经使用过的词一律增加惩罚，即便只出现过一次。
- **取值范围：** `0.0 ~ 2.0`
- **与 frequency penalty 区别：**
  - `frequency penalty` 是对词用得越多惩罚越大；
  - `presence penalty` 是“用过一次就开始惩罚”，鼓励引入新词。

## 提示词工程：一项新兴职业

由于提示词能极大地影响输出质量，因此提示词工程成为一项重要技能。随着越来越多的组织采用LLM AI 模型来自动化任务、提升效率，对提示词工程师的需求也在迅速增长。

优秀的提示词工程师可以帮助企业最大限度地发挥其大语言模型的能力，确保输出满足实际需求。

### 借助 Semantic Kernel 成为提示词工程高手

Semantic Kernel 是提升提示词工程能力的重要工具。它通过统一的接口，让你能够在多个模型之间快速对比不同提示词和参数的效果，实现高效的迭代和调优。

掌握提示词工程之后，你可以使用 Semantic Kernel 将这些技能应用到真实项目中——结合提示词、本地函数与外部系统连接器，构建强大的 AI 应用。

Semantic Kernel 还与 Visual Studio Code 深度集成，让你能够将提示词工程无缝融入现有的开发流程：

- 在熟悉的代码编辑器中直接创建和调试提示词
- 使用现有测试框架为提示词编写单元测试
- 将提示词部署到生产环境，并集成进 CI/CD 流水线


### 提示词工程实战技巧

要成为优秀的提示词工程师，需结合技术、创意与不断实验：

1. 理解大语言模型原理
深入了解模型架构、训练方式与生成机制。

2. 具备领域知识
对特定业务/任务具备认知，以便设计出符合语境的提示。

3. 善于实验调参
反复尝试不同参数和格式以优化效果。

4. 基于反馈迭代优化
根据模型输出与用户反馈持续打磨提示词。

5. 保持学习
关注最新的提示词工程研究、最佳实践与工具更新。

## 结语

提示词工程是一个动态且持续演进的领域。优秀的提示词工程师在发挥 LLM 模型潜力、打造高效 AI 应用方面起着至关重要的作用。

如果你掌握了提示词设计这门“看似细微但极其关键”的技能，你就能真正掌控 AI 的输出行为。

