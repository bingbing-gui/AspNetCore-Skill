## 零样本提示（zero-shot prompting）

如今的大型语言模型（LLMs），如 GPT-3.5 Turbo、GPT-4 和 Claude 3，都经过了指令微调，并在大量数据上进行了训练。大规模训练使这些模型具备了在“零样本”条件下完成某些任务的能力。

零样本提示（zero-shot prompting）是指：与模型交互时使用的提示中不包含任何示例或演示。零样本提示直接通过指令让模型执行任务，而无需额外的示例来引导它。

我们在上一节尝试了一些零样本提示示例。以下是其中一个我们使用过的示例（即文本分类）：

Prompt：

说明：请判断下列句子的情感倾向（正面或负面），如果无法判断，请回答“未知”。

句子：这款手机非常好用，性价比也很高。

情感：

输出：负面

在上面的提示中，我们并没有为模型提供任何带有情感分类标签的示例文本，LLM 已经能够理解“情感”这个概念——这正是其零样本能力在发挥作用。

所谓指令微调，本质上是指在包含明确指令描述的数据集上对模型进行微调。  
[https://arxiv.org/pdf/2109.01652](https://arxiv.org/pdf/2109.01652) 表明微调可以提升零样本学习的效果。

此外，还引入了 [Reinforcement Learning from Human Feedback](https://arxiv.org/abs/1706.03741) 来扩展指令微调的能力，使模型更符合人类偏好。这一最新进展正是驱动 ChatGPT 等模型的关键技术之一。

当零样本提示无法满足需求时，推荐在提示中加入演示或示例，这就转向了少样本提示（few-shot prompting）。

## 少样本提示（few-shot prompting）

少样本提示（few-shot prompting）是指在与大型语言模型（LLM）交互时，提供少量示例来引导模型完成任务。这些示例通常包括输入和期望的输出，帮助模型更好地理解任务要求。此时，可以采用少样本提示（few-shot prompting）作为一种技术手段，启用上下文学习（in-context learning），通过在提示中提供示例来引导模型生成更优的结果。

当模型的规模扩大到足够大时，才首次出现了少样本学习的能力  
[https://arxiv.org/pdf/2302.13971](https://arxiv.org/pdf/2302.13971)

Prompt：

这家餐厅的服务太棒了！正面  
太失望了，再也不来了。 负面  
这个手机用起来非常顺手！正面  
电影实在太烂了，浪费时间。 --  

输出：负面

我们可以观察到，模型仅凭示例就学会了如何执行该任务。对于更复杂的任务，我们可以尝试增加示例数量来进一步提升模型的表现。

## 少样本提示的局限性（Limitations of Few-shot Prompting）

标准的少样本提示在许多任务中表现良好，但并不是一种完美的技术，尤其是在处理更复杂的推理任务时。我们来通过一个例子说明其中的问题。你是否还记得我们之前提供过这样一个任务：

Prompt

这些数字中的奇数加起来是一个偶数：4, 8, 9, 15, 12, 2, 1。  
回答：False

这些数字中的奇数加起来是一个偶数：17, 10, 19, 4, 8, 12, 24。  
回答：True

这些数字中的奇数加起来是一个偶数：16, 11, 14, 4, 8, 13, 24。  
回答：True

这些数字中的奇数加起来是一个偶数：17, 9, 10, 12, 13, 4, 2。  
回答：False

这些数字中的奇数加起来是一个偶数：15, 32, 5, 13, 82, 7, 1。  
回答：

输出：

从示例可以看出，这类任务实际上包含了多个推理步骤。换句话说，如果我们能将问题拆解成步骤，并在提示中逐步演示给模型，可能会有更好的效果。

最近，链式思维提示（Chain-of-Thought Prompting，简称 CoT）被广泛应用于处理更复杂的算术、常识和符号推理任务，效果显著。

总结：  
提供示例（少样本）在某些任务中是有帮助的，但当零样本和少样本提示都无法获得理想结果时，可能意味着模型当前的知识还不足以胜任该任务。

这时候，我们建议：
  
• 考虑对模型进行微调（fine-tuning）；  
• 或尝试更高级的提示技巧，例如接下来将介绍的链式思维提示（Chain-of-Thought Prompting），这是一种正在流行的有效方法。
