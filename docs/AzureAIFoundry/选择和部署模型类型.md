
## 选择模型

模型目录能集中存储和浏览各种模型，尤其在 Azure AI Foundry 中，你可以快速找到并部署适合自己需求的模型。选用合适的基础模型很重要，因为这会直接影响应用效果。可以先思考以下问题：

* 你想要使用AI解决什么样的问题?

Hugging Face、GitHub 或 Azure AI Foundry 三种目录中探索模型，但 Azure AI Foundry 的模型目录提供了更方便的部署和原型构建支持。

接下来可考虑以下选项：

1. 大模型 vs. 小模型  
    * 大模型（如 GPT-4、Mistral Large 等）适合深度推理和复杂生成。  
    * 小模型（如 Phi3、Mistral OSS 小模型等）更高效省成本，也能完成大部分 NLP 任务。

2. 聚焦某种模态、任务或工具  
    * 有些专注文本对话，如 GPT-4、Mistral Large；也有专注推理的模型。  
    * 多模态模型可同时处理图像、文本等，多用于视觉或文档分析。  
    * 图像生成模型（如 DALL·E 3、Stability AI）可根据文本生成图片。  
    * 嵌入模型（如 Ada、Cohere）能将文本转为数值表示，用于提高搜索和推荐。  
    * 支持函数调用与 JSON 处理的模型可更方便与 API 和数据库交互。

3. 行业或区域定制模型  
    * 一些模型专门服务于特定语言或行业，比如阿拉伯语、欧洲语言或金融预测等。

4. 开放模型 vs. 专有模型  
    * 专有模型（如 GPT-4、Mistral Large 等）性能先进且适合企业需求。  
    * 开放模型可灵活微调和成本较低（常见于社群活跃的项目）。

* 选择最好的模型针对问题场景？

为找到最合适模型，你可以关注以下方面：

* 任务类型：你需要模型执行什么类型的任务？它仅包含对文本的理解，还是还包括音频、视频或多模态数据的处理？
* 精度：基础模型是否足够？需不需要微调? 
* 开放性：是否需要自己微调?
* 部署方式：本地、无服务器端点，还是自行管理?


* 模型的性能能否满足真实环境的大规模负载？  

    扩展生成式 AI 解决方案时需要考虑以下因素：

    模型部署：你将在哪里部署模型，以获得性能和成本的最佳平衡？

    模型监控和优化：你将如何监控、评估和优化模型性能？

    提示管理：你将如何协调和优化提示，以最大化生成响应的准确性和相关性？

    模型生命周期：你将如何管理模型、数据和代码更新，作为持续生成式 AI 操作（GenAIOps）生命周期的一部分？

## 部署模型

1. Azure OpenAI 模型（如 GPT-3.5 和 GPT-4）
来源：这些模型由 OpenAI 提供，但通过 Azure OpenAI 服务 部署和托管。

部署方式：模型托管在 Azure 的云平台 上，通过 Azure OpenAI 服务 进行部署和管理。

管理方式：用户通过 Azure 管理门户 或 API 访问和使用这些模型，微软负责模型的管理、更新和基础设施。

适用场景：适用于需要高性能、企业级支持和较强安全性的应用，如文本生成、问答系统等。

2. 第三方模型（如 DeepSeek-R1，作为 Models-as-a-Service）

来源：这些模型是 第三方提供 的，如 DeepSeek-R1，并通过 Azure AI 模型推理 或 无服务器 API 封装提供。

部署方式：模型通常由第三方公司提供，并通过 API 接口与 Azure 进行集成。模型本身并不直接托管在 Azure 上，而是通过 API 封装 来访问。

管理方式：第三方负责模型的管理和更新，用户通过 Azure 提供的 API 调用这些模型。

适用场景：适用于需要集成其他公司或平台提供的专业模型，或者需要灵活选择不同模型的场景。

3. 开源和自定义模型（如 Hugging Face 模型，使用用户管理的计算）
来源：这些模型通常是 开源的，如来自 Hugging Face 的模型，或 自定义训练的模型。

部署方式：用户可以选择在 自己的计算资源（如本地服务器、虚拟机或 Azure 计算服务）上进行部署。这些模型通常是通过 用户管理的计算 来运行。

管理方式：用户负责模型的管理、更新和基础设施配置。用户可以根据需要进行 微调 和 自定义。

适用场景：适用于需要 高度定制化 或 灵活控制 部署环境的场景，如模型微调、特定行业模型等。

核心区别总结：
模型来源：

Azure OpenAI 模型：由 OpenAI 提供，由 Azure 托管。

第三方模型：由 第三方公司提供，通过 API 封装 提供服务。

开源和自定义模型：由 开源社区 或 用户自行训练 提供，用户在自己的 计算资源上部署。

部署和管理：

Azure OpenAI 模型：由 Azure 托管，微软负责基础设施管理。

第三方模型：由 第三方提供，用户通过 API 调用 使用。

开源和自定义模型：由 用户自行管理 和 部署，有较高的灵活性和定制能力。

适用场景：

Azure OpenAI 模型：适合需要 高性能、企业级支持 和安全性的应用。

第三方模型：适合需要 第三方专业模型 或 快速集成外部模型 的应用。

开源和自定义模型：适合需要 高度定制 和 灵活部署 的场景，特别是在模型微调和本地部署方面。

## 测试和改进模型

当模型部署成功，与其交互可通过“提示工程”方法来优化输出质量。高质量的提示能带来更合适的回答。例如：  

* 让模型协助改进问题，获得更精准回答。
* 让模型扮演特定角色提高针对性。
* 提供模板，输出特定格式。  
* 为模型提供额外上下文，提高准确度。

提示工程能让模型更好地理解需求并给出所需答案。

通过这些方法，可让你的生成式 AI 解决方案更加实用、准确并能扩展到真正的业务环境。
